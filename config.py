from pathlib import Path

# ==============================
# 游댢 CONFIGURACI칍N GLOBAL
# ==============================

# 游늭 Carpeta donde est치n los PDFs a analizar
PDF_FOLDER = Path("Muestras de Expedientes")

# 丘뙖잺 Modo de ejecuci칩n
# - "text": usa el texto embebido del PDF
# - "image": procesa el documento como imagen (OCR o visi칩n multimodal)
# - "auto": decide seg칰n el tipo de contenido detectado
MODE = "text"  # cambia a "text", "image" o "auto" seg칰n lo que quieras probar


# ==============================
# 游뱄 CONFIGURACI칍N DE MODELOS
# ==============================

# Si usas un modelo local (por ejemplo, vLLM, Ollama, LM Studio)
USE_LOCAL_MODEL = True

# Modelo a usar
# - Para OpenAI: "gpt-4o-mini", "gpt-4.1", "gpt-5-nano"
# - Para LLM local: el nombre del modelo compatible (por ejemplo, "openai/gpt-oss-20b")
MODEL_TEXT = "openai/gpt-oss-20b"
MODEL_IMAGE = "gpt-5-nano"

# Base URL de la API (por defecto: OpenAI)
# Cambia si usas un servidor local (por ejemplo: http://localhost:8001/v1)
if USE_LOCAL_MODEL:
    BASE_URL = "http://localhost:8001/v1"
else:
    BASE_URL = "https://api.openai.com/v1"


# ==============================
# 丘뙖잺 PAR츼METROS ADICIONALES
# ==============================

# L칤mite de caracteres del texto a enviar al modelo (para ahorrar tokens)
TEXT_TRUNCATE_LIMIT = 15000

# Carpeta temporal para im치genes generadas desde PDFs
TEMP_IMAGE_FOLDER = Path("temp_images")
TEMP_IMAGE_FOLDER.mkdir(exist_ok=True)
